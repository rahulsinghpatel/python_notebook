
[[importing-libraries]]
= 1. Importing libraries


+*In[1]:*+
[source, ipython3]
----
import pandas as pd
----

[[data-loading]]
= 2. Data Loading


+*In[2]:*+
[source, ipython3]
----
data = pd.read_csv("50_Startups.csv")
----


+*In[3]:*+
[source, ipython3]
----
data.head()
----


+*Out[3]:*+
----
[cols=",,,,,",options="header",]
|===========================================================
| |R&D Spend |Administration |Marketing Spend |State |Profit
|0 |165349.20 |136897.80 |471784.10 |New York |192261.83
|1 |162597.70 |151377.59 |443898.53 |California |191792.06
|2 |153441.51 |101145.55 |407934.54 |Florida |191050.39
|3 |144372.41 |118671.85 |383199.62 |New York |182901.99
|4 |142107.34 |91391.77 |366168.42 |Florida |166187.94
|===========================================================
----


+*In[4]:*+
[source, ipython3]
----
data.shape
----


+*Out[4]:*+
----(50, 5)----


+*In[5]:*+
[source, ipython3]
----
X = data.iloc[:, :-1] #independent variables
y = data.iloc[:,4]  #dependent variables
----


+*In[6]:*+
[source, ipython3]
----
X.shape
----


+*Out[6]:*+
----(50, 4)----


+*In[7]:*+
[source, ipython3]
----
type(X)
----


+*Out[7]:*+
----pandas.core.frame.DataFrame----


+*In[8]:*+
[source, ipython3]
----
y.shape
----


+*Out[8]:*+
----(50,)----


+*In[9]:*+
[source, ipython3]
----
type(y)
----


+*Out[9]:*+
----pandas.core.series.Series----


+*In[10]:*+
[source, ipython3]
----
X.head()
----


+*Out[10]:*+
----
[cols=",,,,",options="header",]
|===================================================
| |R&D Spend |Administration |Marketing Spend |State
|0 |165349.20 |136897.80 |471784.10 |New York
|1 |162597.70 |151377.59 |443898.53 |California
|2 |153441.51 |101145.55 |407934.54 |Florida
|3 |144372.41 |118671.85 |383199.62 |New York
|4 |142107.34 |91391.77 |366168.42 |Florida
|===================================================
----


+*In[11]:*+
[source, ipython3]
----
y.head()
----


+*Out[11]:*+
----0    192261.83
1    191792.06
2    191050.39
3    182901.99
4    166187.94
Name: Profit, dtype: float64----

[[data-preprocessing]]
= 3. Data Preprocessing


+*In[12]:*+
[source, ipython3]
----
# LabelEncoder: Encode labels with value between 0 and n_classes-1.
#https://medium.com/@contactsunny/label-encoder-vs-one-hot-encoder-in-machine-learning-3fc273365621
from sklearn.preprocessing import LabelEncoder,OneHotEncoder
----


+*In[13]:*+
[source, ipython3]
----
labelEncoder = LabelEncoder()
labelEncoder.fit(X.iloc[:,3])
X.iloc[:,3] = labelEncoder.transform(X.iloc[:,3])
----


+*In[14]:*+
[source, ipython3]
----
X.head()
----


+*Out[14]:*+
----
[cols=",,,,",options="header",]
|===================================================
| |R&D Spend |Administration |Marketing Spend |State
|0 |165349.20 |136897.80 |471784.10 |2
|1 |162597.70 |151377.59 |443898.53 |0
|2 |153441.51 |101145.55 |407934.54 |1
|3 |144372.41 |118671.85 |383199.62 |2
|4 |142107.34 |91391.77 |366168.42 |1
|===================================================
----

'''''

That’s all label encoding is about. But depending on the data, label
encoding introduces a new problem. For example, we have encoded a set of
country names into numerical data. This is actually categorical data and
there is no relation, of any kind, between the rows.

The problem here is, since there are different numbers in the same
column, the model will misunderstand the data to be in some kind of
order, 0 < 1 < 2. But this isn’t the case at all. To overcome this
problem, we use One Hot Encoder. ___________


+*In[15]:*+
[source, ipython3]
----
onehot = OneHotEncoder(categorical_features=[3])
----


+*In[16]:*+
[source, ipython3]
----
X = onehot.fit_transform(X).toarray()
----


+*Out[16]:*+
----
/Users/admin/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/_encoders.py:368: FutureWarning: The handling of integer data will change in version 0.22. Currently, the categories are determined based on the range [0, max(values)], while in the future they will be determined based on the unique values.
If you want the future behaviour and silence this warning, you can specify "categories='auto'".
In case you used a LabelEncoder before this OneHotEncoder to convert the categories to integers, then you can now use the OneHotEncoder directly.
  warnings.warn(msg, FutureWarning)
/Users/admin/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/_encoders.py:390: DeprecationWarning: The 'categorical_features' keyword is deprecated in version 0.20 and will be removed in 0.22. You can use the ColumnTransformer instead.
  "use the ColumnTransformer instead.", DeprecationWarning)
----
onehot.fit_transform(X).toarray()

/Users/admin/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/_encoders.py:368: FutureWarning: The handling of integer data will change in version 0.22. Currently, the categories are determined based on the range [0, max(values)], while in the future they will be determined based on the unique values.
If you want the future behaviour and silence this warning, you can specify "categories='auto'".
In case you used a LabelEncoder before this OneHotEncoder to convert the categories to integers, then you can now use the OneHotEncoder directly.
  warnings.warn(msg, FutureWarning)
  
  
/Users/admin/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/_encoders.py:390: DeprecationWarning: The 'categorical_features' keyword is deprecated in version 0.20 and will be removed in 0.22. You can use the ColumnTransformer instead.
  "use the ColumnTransformer instead.", DeprecationWarning)

+*In[17]:*+
[source, ipython3]
----
type(X)
----


+*Out[17]:*+
----numpy.ndarray----


+*In[18]:*+
[source, ipython3]
----
X = X[:, 1:] #Removing first colums from ndarray
----


+*In[19]:*+
[source, ipython3]
----
X[:5]
----


+*Out[19]:*+
----array([[0.0000000e+00, 1.0000000e+00, 1.6534920e+05, 1.3689780e+05,
        4.7178410e+05],
       [0.0000000e+00, 0.0000000e+00, 1.6259770e+05, 1.5137759e+05,
        4.4389853e+05],
       [1.0000000e+00, 0.0000000e+00, 1.5344151e+05, 1.0114555e+05,
        4.0793454e+05],
       [0.0000000e+00, 1.0000000e+00, 1.4437241e+05, 1.1867185e+05,
        3.8319962e+05],
       [1.0000000e+00, 0.0000000e+00, 1.4210734e+05, 9.1391770e+04,
        3.6616842e+05]])----

[[data-splitting]]
= 4. Data Splitting


+*In[20]:*+
[source, ipython3]
----
from sklearn.model_selection import train_test_split # preciously it was 
----


+*In[21]:*+
[source, ipython3]
----
X_train,X_test,y_train,y_test = train_test_split(X, y, test_size=0.2, random_state=42)
----


+*In[22]:*+
[source, ipython3]
----
X_train.shape, X_test.shape, y_train.shape, y_test.shape
----


+*Out[22]:*+
----((40, 5), (10, 5), (40,), (10,))----

[[model]]
= 5. Model


+*In[23]:*+
[source, ipython3]
----
from sklearn.linear_model import LinearRegression
----


+*In[25]:*+
[source, ipython3]
----
LinearRegression()
----


+*Out[25]:*+
----LinearRegression(copy_X=True, fit_intercept=True, n_jobs=None,
         normalize=False)----


+*In[24]:*+
[source, ipython3]
----
linearRegression = LinearRegression()
----


+*In[ ]:*+
[source, ipython3]
----

----
